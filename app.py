import os
import torch
import torch.nn as nn
from torchvision import transforms, models
from torchvision.models import resnet50
from PIL import Image
import io
import base64
from flask import Flask, request, jsonify, render_template
import numpy as np
import requests

app = Flask(__name__)

# ============ 1ï¸âƒ£ Ù…Ø¯Ù„ ResNet50 Ø®ÙˆØ¯Øª ============
class IBDResNet(nn.Module):
    def __init__(self, num_classes=3):
        super(IBDResNet, self).__init__()
        self.backbone = resnet50(weights=None)
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        return self.classifier(features)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = IBDResNet(num_classes=3)

try:
    checkpoint = torch.load('models/final_ibd_model.pth', map_location=device)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    print("âœ… Ù…Ø¯Ù„ ResNet50 Ù„ÙˆØ¯ Ø´Ø¯")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ù…Ø¯Ù„: {e}")

model = model.to(device)
model.eval()

# Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§
class_names = ['normal', 'crohn', 'ulcerative-colitis']
class_names_fa = {
    'normal': 'Ù†Ø±Ù…Ø§Ù„',
    'crohn': 'Ú©Ø±ÙˆÙ†',
    'ulcerative-colitis': 'Ú©ÙˆÙ„ÛŒØª Ø§ÙˆÙ„Ø³Ø±Ø§ØªÛŒÙˆ'
}

# Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ============ 2ï¸âƒ£ Ù„Ø§Ù…Ø§ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ============
OPENROUTER_API_KEY = "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"

def format_with_llm(disease_fa, confidence):
    """
    ÙÙ‚Ø· Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†ØªÛŒØ¬Ù‡ - Ø¨Ø¯ÙˆÙ† ØªØ­Ù„ÛŒÙ„ Ø§Ø¶Ø§ÙÙ‡
    """
    
    prompt = f"""Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø±ØŒ Ø§ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ ØªØ´Ø®ÛŒØµ Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø±ÙˆØ§Ù† Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†:

ØªØ´Ø®ÛŒØµ: {disease_fa}
Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {confidence:.1%}

ÙÙ‚Ø· ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÙ‡."""
    
    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "Content-Type": "application/json",
            },
            json={
                "model": "meta-llama/llama-3.2-11b-vision-instruct:free",
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 50,  # ÙÙ‚Ø· ÛŒÙ‡ Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡
                "temperature": 0.3,
            },
            timeout=5
        )
        
        result = response.json()
        return result["choices"][0]["message"]["content"].strip()
        
    except:
        # Ø§Ú¯Ø± Ù„Ø§Ù…Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨ÙˆØ¯ØŒ Ø¬Ù…Ù„Ù‡ Ø³Ø§Ø¯Ù‡ Ø®ÙˆØ¯Ù…ÙˆÙ†
        return f"ØªØ´Ø®ÛŒØµ: {disease_fa} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence:.1%}"

# ============ 3ï¸âƒ£ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ ============
@app.route('/')
def index():
    return render_template('chat.html')

# ============ 4ï¸âƒ£ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ + Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ Ù„Ø§Ù…Ø§ ============
@app.route('/api/predict', methods=['POST'])
def predict():
    try:
        data = request.json
        image_data = data.get('image')
        
        if not image_data:
            return jsonify({'error': 'Ø¹Ú©Ø³ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡'}), 400
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ ResNet50
        input_tensor = transform(image).unsqueeze(0).to(device)
        
        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, prediction = torch.max(probabilities, 1)
        
        class_idx = prediction.item()
        class_name = class_names[class_idx]
        class_name_fa = class_names_fa[class_name]
        confidence_score = confidence.item()
        
        # ğŸŸ¡ Ù„Ø§Ù…Ø§ ÙÙ‚Ø· Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÛŒÚ©Ù†Ù‡
        llm_sentence = format_with_llm(class_name_fa, confidence_score)
        
        return jsonify({
            'class': class_name,
            'class_fa': class_name_fa,
            'confidence': float(confidence_score),
            'confidence_percent': f"{confidence_score*100:.1f}%",
            'explanation': llm_sentence,  # ÙÙ‚Ø· ÛŒÙ‡ Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡
            'model': 'ResNet50 + Llama (formatting)'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
