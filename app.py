import os
import torch
import torch.nn as nn
from torchvision import transforms, models
from torchvision.models import resnet50
from PIL import Image
import io
import base64
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import numpy as np
import requests
import json
from datetime import datetime

app = Flask(__name__)
CORS(app)

# ============ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ============
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ Server starting on {DEVICE}")

# ============ Groq API - Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ÙØ¹Ø§Ù„ ============
GROQ_API_KEY = "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"
GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"

# Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ
CLASS_NAMES = ['normal', 'crohn', 'ulcerative-colitis']
CLASS_NAMES_FA = {
    'normal': 'Ù†Ø±Ù…Ø§Ù„',
    'crohn': 'Ú©Ø±ÙˆÙ†',
    'ulcerative-colitis': 'Ú©ÙˆÙ„ÛŒØª Ø§ÙˆÙ„Ø³Ø±Ø§ØªÛŒÙˆ'
}

# ============ Ù…Ø¯Ù„ ResNet50 ============
class IBDResNet(nn.Module):
    def __init__(self, num_classes=3):
        super(IBDResNet, self).__init__()
        self.backbone = resnet50(weights=None)
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        return self.classifier(features)

# ============ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ============
model = None
model_loaded = False

try:
    model_path = 'models/final_ibd_model.pth'
    if os.path.exists(model_path):
        print(f"ğŸ“‚ ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ Ù¾ÛŒØ¯Ø§ Ø´Ø¯: {model_path}")
        model = IBDResNet(num_classes=3)
        
        checkpoint = torch.load(model_path, map_location=DEVICE)
        
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        model = model.to(DEVICE)
        model.eval()
        model_loaded = True
        
        model_size = os.path.getsize(model_path) / (1024 * 1024)
        print(f"âœ… Ù…Ø¯Ù„ ResNet50 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù„ÙˆØ¯ Ø´Ø¯")
        print(f"   - Device: {DEVICE}")
        print(f"   - Ø­Ø¬Ù… ÙØ§ÛŒÙ„: {model_size:.1f} MB")
    else:
        print(f"âŒ ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ ÛŒØ§ÙØª Ù†Ø´Ø¯: {model_path}")
        
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ù…Ø¯Ù„: {e}")
    import traceback
    traceback.print_exc()

# ============ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± ============
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ============ ØªØ§Ø¨Ø¹ Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ Groq ============
def format_with_groq(disease_fa, confidence):
    """Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ Groq Llama 3.3 (Ø±Ø§ÛŒÚ¯Ø§Ù† - ÙØ¹Ø§Ù„)"""
    
    prompts = {
        'normal': f"ØªØ´Ø®ÛŒØµ: {disease_fa} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence:.1f}%. ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ú©Ù‡ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨Ø¯Ù‡Ø¯ Ùˆ Ø¨Ú¯ÙˆÛŒØ¯ Ù†Ú¯Ø±Ø§Ù† Ù†Ø¨Ø§Ø´Ø¯ Ø¨Ù†ÙˆÛŒØ³.",
        'crohn': f"ØªØ´Ø®ÛŒØµ: {disease_fa} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence:.1f}%. ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯Ù„Ø³ÙˆØ²Ø§Ù†Ù‡ Ú©Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ù‡ Ù…Ø´ÙˆØ±Øª Ø¨Ø§ Ù¾Ø²Ø´Ú© Ù…ØªØ®ØµØµ ØªØ´ÙˆÛŒÙ‚ Ú©Ù†Ø¯ Ø¨Ù†ÙˆÛŒØ³.",
        'ulcerative-colitis': f"ØªØ´Ø®ÛŒØµ: {disease_fa} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence:.1f}%. ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯Ù„Ø³ÙˆØ²Ø§Ù†Ù‡ Ú©Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ù‡ Ù¾ÛŒÚ¯ÛŒØ±ÛŒ Ø¯Ø±Ù…Ø§Ù† Ùˆ Ù…Ø´ÙˆØ±Øª Ø¨Ø§ Ù¾Ø²Ø´Ú© ØªØ´ÙˆÛŒÙ‚ Ú©Ù†Ø¯ Ø¨Ù†ÙˆÛŒØ³."
    }
    
    if 'Ù†Ø±Ù…Ø§Ù„' in disease_fa:
        prompt_key = 'normal'
    elif 'Ú©Ø±ÙˆÙ†' in disease_fa:
        prompt_key = 'crohn'
    else:
        prompt_key = 'ulcerative-colitis'
    
    prompt = prompts.get(prompt_key, f"ØªØ´Ø®ÛŒØµ: {disease_fa} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence:.1f}%. ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø¨Ù†ÙˆÛŒØ³.")
    
    try:
        response = requests.post(
            GROQ_URL,
            headers={
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "llama-3.3-70b-versatile",
                "messages": [
                    {"role": "system", "content": "ØªÙˆ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù¾Ø²Ø´Ú©ÛŒ Ù…Ù‡Ø±Ø¨Ø§Ù† Ù‡Ø³ØªÛŒ. Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒØŒ Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ø¯Ù‡. Ø§Ø² Ú©Ù„Ù…Ø§Øª ØªØ®ØµØµÛŒ Ø³Ù†Ú¯ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 80,
                "temperature": 0.4
            },
            timeout=15
        )
        
        if response.status_code == 200:
            result = response.json()
            reply = result["choices"][0]["message"]["content"].strip()
            reply = reply.strip('"').strip("'").strip()
            print(f"ğŸŸ¡ Groq 70B Ù¾Ø§Ø³Ø®: {reply}")
            return reply
        else:
            print(f"âš ï¸ Groq 70B Ø®Ø·Ø§: {response.status_code}")
            return fallback_groq_8b(disease_fa, confidence)
            
    except Exception as e:
        print(f"âš ï¸ Groq 70B Ø®Ø·Ø§: {e}")
        return fallback_groq_8b(disease_fa, confidence)

def fallback_groq_8b(disease_fa, confidence):
    """Ù…Ø¯Ù„ Ù¾Ø´ØªÛŒØ¨Ø§Ù† - Ø³Ø±ÛŒØ¹ØªØ±"""
    try:
        response = requests.post(
            GROQ_URL,
            headers={
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": "llama-3.1-8b-instant",
                "messages": [
                    {"role": "system", "content": "Ù¾Ø§Ø³Ø® ÙØ§Ø±Ø³ÛŒ Ú©ÙˆØªØ§Ù‡."},
                    {"role": "user", "content": f"ØªØ´Ø®ÛŒØµ: {disease_fa} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence:.1f}%. ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡ Ø¨Ù†ÙˆÛŒØ³."}
                ],
                "max_tokens": 60,
                "temperature": 0.3
            },
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            reply = result["choices"][0]["message"]["content"].strip()
            print(f"ğŸŸ¢ Groq 8B Ù¾Ø§Ø³Ø®: {reply}")
            return reply
        else:
            return f"âœ… ØªØ´Ø®ÛŒØµ: {disease_fa} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence:.1f}%"
            
    except Exception as e:
        print(f"âš ï¸ Groq 8B Ø®Ø·Ø§: {e}")
        return f"âœ… ØªØ´Ø®ÛŒØµ: {disease_fa} Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence:.1f}%"

# ============ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ API ============

@app.route('/')
def index():
    """ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ú†Øª Ø¨Ø§Øª"""
    return render_template('chat.html')

@app.route('/health')
def health():
    """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆØ±"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_loaded,
        'device': str(DEVICE),
        'timestamp': datetime.now().isoformat(),
        'groq_ready': GROQ_API_KEY is not None
    })

@app.route('/api/test', methods=['GET'])
def test():
    """ØªØ³Øª Ø³Ø§Ø¯Ù‡ API"""
    return jsonify({
        'success': True,
        'message': 'Ø³Ø±ÙˆØ± Crohn IBD Detector ÙØ¹Ø§Ù„ Ø§Ø³Øª',
        'model_loaded': model_loaded,
        'device': str(DEVICE),
        'llm_configured': GROQ_API_KEY is not None,
        'active_model': 'llama-3.3-70b-versatile',
        'fallback_model': 'llama-3.1-8b-instant'
    })

@app.route('/api/test-groq', methods=['GET'])
def test_groq():
    """ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ Groq"""
    try:
        test_response = format_with_groq("Ú©Ø±ÙˆÙ†", 87.5)
        if test_response and not test_response.startswith('âœ…'):
            return jsonify({
                'success': True,
                'message': 'Ø§ØªØµØ§Ù„ Ø¨Ù‡ Groq Ø¨Ø±Ù‚Ø±Ø§Ø± Ø§Ø³Øª',
                'response': test_response,
                'model_used': 'llama-3.3-70b-versatile'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Groq Ù¾Ø§Ø³Ø® Ù†Ø¯Ø§Ø¯',
                'fallback_used': True
            }), 503
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/predict', methods=['POST'])
def predict():
    """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØµÙˆÛŒØ± Ø¢Ù†Ø¯ÙˆØ³Ú©ÙˆÙ¾ÛŒ"""
    
    if not model_loaded:
        return jsonify({
            'success': False,
            'error': 'Ù…Ø¯Ù„ Ù‡Ù†ÙˆØ² Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ú†Ù†Ø¯ Ù„Ø­Ø¸Ù‡ Ø¯ÛŒÚ¯Ø± ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.'
        }), 503
    
    try:
        data = request.json
        if not data:
            return jsonify({'success': False, 'error': 'Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø®Ø§Ù„ÛŒ Ø§Ø³Øª'}), 400
        
        image_data = data.get('image')
        if not image_data:
            return jsonify({'success': False, 'error': 'Ø¹Ú©Ø³ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡'}), 400
        
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        try:
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        except Exception as e:
            return jsonify({'success': False, 'error': 'ÙØ±Ù…Øª ØªØµÙˆÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª'}), 400
        
        input_tensor = transform(image).unsqueeze(0).to(DEVICE)
        
        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, prediction = torch.max(probabilities, 1)
        
        class_idx = prediction.item()
        class_name = CLASS_NAMES[class_idx]
        class_name_fa = CLASS_NAMES_FA[class_name]
        confidence_score = confidence.item()
        
        print(f"âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {class_name_fa} | Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {confidence_score:.1%}")
        
        groq_response = format_with_groq(class_name_fa, confidence_score * 100)
        
        if not groq_response:
            if class_name == 'normal':
                groq_response = f"âœ… ØªØµÙˆÛŒØ± Ø¢Ù†Ø¯ÙˆØ³Ú©ÙˆÙ¾ÛŒ Ø´Ù…Ø§ Ù†Ø±Ù…Ø§Ù„ Ø§Ø³Øª. Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence_score*100:.1f}% Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø§Ù„ØªÙ‡Ø§Ø¨ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù†Ø´Ø¯."
            elif class_name == 'crohn':
                groq_response = f"âš ï¸ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence_score*100:.1f}%ØŒ ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ú©Ø±ÙˆÙ† Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª. ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¨Ø§ Ù¾Ø²Ø´Ú© Ù…ØªØ®ØµØµ Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯."
            else:
                groq_response = f"âš ï¸ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence_score*100:.1f}%ØŒ ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ Ø¨Ø§ Ú©ÙˆÙ„ÛŒØª Ø§ÙˆÙ„Ø³Ø±Ø§ØªÛŒÙˆ Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù‚Ø·Ø¹ÛŒ Ø¨Ù‡ Ù¾Ø²Ø´Ú© Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯."
        
        return jsonify({
            'success': True,
            'class': class_name,
            'class_fa': class_name_fa,
            'confidence': float(confidence_score),
            'confidence_percent': f"{confidence_score*100:.1f}%",
            'explanation': groq_response,
            'groq_used': groq_response is not None and not groq_response.startswith('âœ…') and not groq_response.startswith('âš ï¸'),
            'model': 'ResNet50 + Groq Llama 3.3'
        })
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø³Ø±ÙˆØ±: {str(e)}'
        }), 500

# ============ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ ============
if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    print("\n" + "="*60)
    print("ğŸš€ Crohn IBD Detector Server - Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ")
    print("="*60)
    print(f"ğŸŒ Server running on port {port}")
    print(f"ğŸ§  Ù…Ø¯Ù„ ResNet50: {'âœ… Ù„ÙˆØ¯ Ø´Ø¯' if model_loaded else 'âŒ Ù„ÙˆØ¯ Ù†Ø´Ø¯'}")
    print(f"ğŸ¦™ Groq API: âœ… ÙØ¹Ø§Ù„ (llama-3.3-70b-versatile)")
    print(f"âš¡ Fallback: âœ… ÙØ¹Ø§Ù„ (llama-3.1-8b-instant)")
    print(f"ğŸ“¡ Endpoints:")
    print(f"   - GET  /")
    print(f"   - GET  /health")
    print(f"   - GET  /api/test")
    print(f"   - GET  /api/test-groq")
    print(f"   - POST /api/predict")
    print("="*60 + "\n")
    
    app.run(host='0.0.0.0', port=port)
