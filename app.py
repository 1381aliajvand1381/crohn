import os
import torch
import torch.nn as nn
from torchvision import transforms, models
from torchvision.models import resnet50
from PIL import Image
import io
import base64
from flask import Flask, request, jsonify, render_template
import numpy as np
import requests
import json

app = Flask(__name__)

# ============ 1ï¸âƒ£ Ù…Ø¯Ù„ ResNet50 Ø®ÙˆØ¯Øª ============
class IBDResNet(nn.Module):
    def __init__(self, num_classes=3):
        super(IBDResNet, self).__init__()
        self.backbone = resnet50(weights=None)
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        return self.classifier(features)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = IBDResNet(num_classes=3)

try:
    checkpoint = torch.load('models/final_ibd_model.pth', map_location=device)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    print("âœ… Ù…Ø¯Ù„ ResNet50 Ù„ÙˆØ¯ Ø´Ø¯")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ù…Ø¯Ù„: {e}")

model = model.to(device)
model.eval()

# Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§
class_names = ['normal', 'crohn', 'ulcerative-colitis']
class_names_fa = {
    'normal': 'Ù†Ø±Ù…Ø§Ù„',
    'crohn': 'Ú©Ø±ÙˆÙ†',
    'ulcerative-colitis': 'Ú©ÙˆÙ„ÛŒØª Ø§ÙˆÙ„Ø³Ø±Ø§ØªÛŒÙˆ'
}

# Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ============ 2ï¸âƒ£ LLM Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ============
OPENROUTER_API_KEY = "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"
SITE_URL = "https://crohn-1.onrender.com"
SITE_NAME = "Crohn IBD Detector"

def generate_llm_response(disease_name, confidence, language='fa'):
    """
    Ø§Ø±Ø³Ø§Ù„ Ù†ØªÛŒØ¬Ù‡ Ù…Ø¯Ù„ Ø¨Ù‡ LLM Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    """
    
    # Ø²Ø¨Ø§Ù† Ú©Ø§Ø±Ø¨Ø±
    lang_instruction = "Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡." if language == 'fa' else "Answer in English."
    
    # Ù¾Ø±Ø§Ù…Ù¾Øª Ù‡ÙˆØ´Ù…Ù†Ø¯
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù¾Ø²Ø´Ú©ÛŒ Ù…ØªØ®ØµØµ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ú¯ÙˆØ§Ø±Ø´ÛŒ Ù‡Ø³ØªÛŒØ¯.
    
    Ù†ØªÛŒØ¬Ù‡ ØªØ´Ø®ÛŒØµ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:
    - Ø¨ÛŒÙ…Ø§Ø±ÛŒ: {disease_name}
    - Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {confidence:.1%}
    
    ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§:
    1. Ø§ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø±ÙˆØ§Ù† Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡
    2. Ø§Ú¯Ø± Ø¨ÛŒÙ…Ø§Ø±ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± ØªÙˆØµÛŒÙ‡ Ú©Ù† Ø¨Ø§ Ù¾Ø²Ø´Ú© Ù…Ø´ÙˆØ±Øª Ú©Ù†Ø¯
    3. Ø§Ú¯Ø± Ù†Ø±Ù…Ø§Ù„ Ø§Ø³ØªØŒ Ø¨Ø§ Ø¢Ø±Ø§Ù…Ø´ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø§Ø·Ù„Ø§Ø¹ Ø¨Ø¯Ù‡
    4. Ø§Ø² Ú©Ù„Ù…Ø§Øª ØªØ®ØµØµÛŒ Ø³Ù†Ú¯ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†
    
    {lang_instruction}
    """
    
    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": SITE_URL,
                "X-Title": SITE_NAME,
            },
            json={
                "model": "meta-llama/llama-3.2-11b-vision-instruct:free",
                "messages": [
                    {"role": "system", "content": "ØªÙˆ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù¾Ø²Ø´Ú©ÛŒ Ù‡Ø³ØªÛŒ Ú©Ù‡ Ù†ØªØ§ÛŒØ¬ ØªØ´Ø®ÛŒØµ Ø±Ø§ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø³Ø§Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒ."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 200,
                "temperature": 0.3,
            },
            timeout=10
        )
        
        result = response.json()
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            # fallback Ø¨Ù‡ Ø¬Ù…Ù„Ù‡ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            return get_fallback_response(disease_name, confidence)
            
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ LLM: {e}")
        return get_fallback_response(disease_name, confidence)

def get_fallback_response(disease_name, confidence):
    """Ø¬Ù…Ù„Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ LLM"""
    confidence_percent = f"{confidence*100:.1f}%"
    
    fallbacks = {
        'normal': f"âœ… ØªØµÙˆÛŒØ± Ø¢Ù†Ø¯ÙˆØ³Ú©ÙˆÙ¾ÛŒ Ø´Ù…Ø§ Ù†Ø±Ù…Ø§Ù„ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯. Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† {confidence_percent} Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø§Ù„ØªÙ‡Ø§Ø¨ ÛŒØ§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù†Ø´Ø¯.",
        'crohn': f"âš ï¸ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ø§ Ø¯Ù‚Øª {confidence_percent}ØŒ ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ú©Ø±ÙˆÙ† Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª. ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù‚Ø·Ø¹ÛŒ Ø¨Ù‡ Ù¾Ø²Ø´Ú© Ù…ØªØ®ØµØµ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯.",
        'ulcerative-colitis': f"âš ï¸ ØªØµÙˆÛŒØ± Ø´Ù…Ø§ Ø¨Ø§ Ø§Ø­ØªÙ…Ø§Ù„ {confidence_percent} Ø¹Ù„Ø§Ø¦Ù… Ú©ÙˆÙ„ÛŒØª Ø§ÙˆÙ„Ø³Ø±Ø§ØªÛŒÙˆ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¨ÛŒØ´ØªØ± Ø¨Ø§ Ù¾Ø²Ø´Ú© Ø®ÙˆØ¯ Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯."
    }
    
    return fallbacks.get(disease_name, "Ù†ØªÛŒØ¬Ù‡ ØªØ´Ø®ÛŒØµ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯.")

# ============ 3ï¸âƒ£ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ ============
@app.route('/')
def index():
    return render_template('chat.html')

# ============ 4ï¸âƒ£ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ + LLM ============
@app.route('/api/predict', methods=['POST'])
def predict():
    try:
        data = request.json
        image_data = data.get('image')
        language = data.get('language', 'fa')  # Ø²Ø¨Ø§Ù† Ú©Ø§Ø±Ø¨Ø±
        
        if not image_data:
            return jsonify({'error': 'Ø¹Ú©Ø³ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡'}), 400
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ ResNet50
        input_tensor = transform(image).unsqueeze(0).to(device)
        
        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, prediction = torch.max(probabilities, 1)
        
        class_idx = prediction.item()
        class_name = class_names[class_idx]
        class_name_fa = class_names_fa[class_name]
        confidence_score = confidence.item()
        
        # ğŸŸ¡ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ LLM Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
        llm_response = generate_llm_response(
            disease_name=class_name_fa,
            confidence=confidence_score,
            language=language
        )
        
        return jsonify({
            'class': class_name,
            'class_fa': class_name_fa,
            'confidence': float(confidence_score),
            'confidence_percent': f"{confidence_score*100:.1f}%",
            'explanation': llm_response,  # âœ… Ù¾Ø§Ø³Ø® LLM
            'fallback': False
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
